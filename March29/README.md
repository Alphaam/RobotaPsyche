1. What are the reasons to not give robots rights and how are they less valid than the reasons for why they deserve rights? The readings argue for robots having rights and present many reasons why they should. The fact that the readings have to argue for this inherently means that there exists reasons against this that they are  arguing against and I am wondering the discussion on the other end(why robots do not deserve rights) looks like.

2.'I argue that is a machine exhibits behaviour of a type normally regarded to as conciousness (whatever conciousness might be) then we should accept that a machine has conciousness" How valid is this approach given that there is an admission of the subjectivity and ambiguity surrounding what conciousness means/looks like but still listing machines as objectively concious based on a metric no one can define?

3. The Mirror test as a test for conciousness in robots: how does it help distinguish having conciousness from acting concious? I understand that animals, who we believe to be concious beings, pass the test and so if robots do too then they are concious is the metric used in this instance, however robots are not animals in any immediate way. How, then, can we truly rule out the other criteria that could cause robots to behave like animals(pretentious conciousness) using this test and the other tests listed to be able to say that robots are concious beings?

4. Evidence shows that some things without conciousness have rights see this [link](https://law.hofstra.edu/pdf/academics/journals/lawreview/lrv_issues_v37n03_cc4_smolensky_final.pdf). Why, then, do robots need to meet the requirement of conciousness to have rights?
